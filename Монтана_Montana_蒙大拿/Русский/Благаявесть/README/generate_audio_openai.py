#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∂–∏–≤–æ–≥–æ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ OpenAI TTS –¥–ª—è –ö–ª–∞–Ω –ú–æ–Ω—Ç–∞–Ω–∞ üìï
–ì–æ–ª–æ—Å: onyx (–≥–ª—É–±–æ–∫–∏–π), nova (–∂–µ–Ω—Å–∫–∏–π), alloy (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π)
–ú–æ–¥–µ–ª—å: tts-1-hd (–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python3 generate_audio_openai.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É.md> [–≥–æ–ª–æ—Å]

–ì–æ–ª–æ—Å–∞: onyx (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), nova, alloy, echo, fable, shimmer

API –∫–ª—é—á –±–µ—Ä—ë—Ç—Å—è –∏–∑ macOS Keychain (montana/OPENAI_API_KEY)
"""

import os
import re
import sys
import subprocess
import tempfile
from pathlib import Path


# === –ù–ê–°–¢–†–û–ô–ö–ò ===
MODEL = "tts-1-hd"
DEFAULT_VOICE = "onyx"
MAX_CHUNK_CHARS = 4000  # OpenAI limit 4096, —Å –∑–∞–ø–∞—Å–æ–º
RESPONSE_FORMAT = "mp3"


def get_api_key() -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç OpenAI API –∫–ª—é—á –∏–∑ macOS Keychain"""
    try:
        result = subprocess.run(
            ["security", "find-generic-password", "-a", "montana",
             "-s", "OPENAI_API_KEY", "-w"],
            capture_output=True, text=True
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except Exception:
        pass

    key = os.environ.get("OPENAI_API_KEY", "")
    if key:
        return key

    print("‚úó OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ keychain, –Ω–∏ –≤ env")
    sys.exit(1)


def clean_text_for_audio(md_content: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ markdown ‚Üí —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏"""

    lines = md_content.split('\n')
    audio_lines = []

    skip_patterns = [
        r'^---+$',
        r'^\*¬´–ö–ª–∞–Ω –ú–æ–Ω—Ç–∞–Ω–∞',
        r'^\*¬´–ö–Ω–∏–≥–∞ –ú–æ–Ω—Ç–∞–Ω–∞',
        r'^\*–ú—ã—Å–ª—å\s',
        r'^\*–î–µ–Ω—å\s',
        r'^\*–î–æ –ø–µ—Ä–≤–æ–≥–æ',
        r'^\*–ë–ª–∞–≥–∞—è–≤–µ—Å—Ç—å',
        r'^\*¬´–ö—Ä–∞—Å–Ω–∞—è',
        r'^\*¬´–ü–µ—Ä–≤–∞—è',
        r'^\d+\.\d+\.\d+',
        r'^Alejandro',
        r'^–ê–ª–µ—Ö–∞–Ω–¥—Ä–æ',
        r'^–ö–ª–æ–¥ –ú–æ–Ω—Ç–∞–Ω–∞',
        r'^ÈáëÂÖÉ',
        r'^‚æ¶ÂÖÉ',
        r'^‚Üí',
        r'^#\w+',
        r'^\|',
        r'^–ù–∞–π–¥—ë–º—Å—è\.$',
    ]

    in_code_block = False

    for line in lines:
        stripped = line.strip()

        if stripped.startswith('```'):
            in_code_block = not in_code_block
            continue
        if in_code_block:
            continue

        if any(re.match(p, stripped) for p in skip_patterns):
            continue

        if not stripped:
            continue

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ ‚Üí —Ç–µ–∫—Å—Ç —Å –ø–∞—É–∑–æ–π
        if line.startswith('#'):
            title = re.sub(r'^#+\s*', '', line).strip()
            title = re.sub(r'\s*`\[\d+:\d+\]`', '', title)
            if title:
                audio_lines.append(f"\n{title}.\n")
            continue

        text = stripped

        # Markdown ‚Üí —Ç–µ–∫—Å—Ç
        text = re.sub(r'\[([^\]]+?)\]\([^\)]+?\)', r'\1', text)
        text = re.sub(r'https?://\S+', '', text)
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        text = re.sub(r'\*(.+?)\*', r'\1', text)
        text = re.sub(r'`([^`]+?)`', r'\1', text)
        text = re.sub(r'^>\s*', '', text)
        text = re.sub(r'^[-‚Ä¢]\s+', '', text)
        text = re.sub(r'[…à]', '', text)
        text = text.replace('üìï', '')
        text = re.sub(r'\s+', ' ', text).strip()

        if text:
            audio_lines.append(text)

    return '\n'.join(audio_lines)


def split_into_chunks(text: str, max_chars: int = MAX_CHUNK_CHARS) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""

    sentences = re.split(r'(?<=[.!?‚Ä¶¬ª])\s+', text)
    chunks = []
    current = ""

    for sentence in sentences:
        if not sentence.strip():
            continue

        if len(current) + len(sentence) + 1 > max_chars:
            if current:
                chunks.append(current.strip())
            current = sentence
        else:
            current = f"{current} {sentence}" if current else sentence

    if current.strip():
        chunks.append(current.strip())

    return chunks


def generate_chunk_audio(client, text: str, voice: str, output_path: Path) -> bool:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫—É—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    try:
        response = client.audio.speech.create(
            model=MODEL,
            voice=voice,
            input=text,
            response_format=RESPONSE_FORMAT
        )
        response.stream_to_file(str(output_path))
        return True
    except Exception as e:
        print(f"  ‚úó –û—à–∏–±–∫–∞: {e}")
        return False


def concatenate_mp3(chunk_files: list[Path], output_path: Path) -> bool:
    """–°–∫–ª–µ–∏–≤–∞–µ—Ç mp3 —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ ffmpeg"""
    if len(chunk_files) == 1:
        chunk_files[0].rename(output_path)
        return True

    # –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è ffmpeg
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for cf in chunk_files:
            f.write(f"file '{cf}'\n")
        list_file = f.name

    try:
        result = subprocess.run(
            ["ffmpeg", "-y", "-f", "concat", "-safe", "0",
             "-i", list_file, "-c", "copy", str(output_path)],
            capture_output=True, text=True
        )
        return result.returncode == 0
    finally:
        os.unlink(list_file)
        for cf in chunk_files:
            if cf.exists():
                cf.unlink()


def main():
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 generate_audio_openai.py <—Ñ–∞–π–ª.md> [–≥–æ–ª–æ—Å]")
        print("\n–ì–æ–ª–æ—Å–∞: onyx (default), nova, alloy, echo, fable, shimmer")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python3 generate_audio_openai.py '01. –°–∏–º—É–ª—è—Ü–∏—è.md'")
        print("  python3 generate_audio_openai.py '01. –°–∏–º—É–ª—è—Ü–∏—è.md' nova")
        return

    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    arg_path = Path(sys.argv[1])
    if arg_path.is_absolute():
        input_file = arg_path
    else:
        input_file = Path.cwd() / arg_path
    input_file = input_file.resolve()

    if not input_file.exists():
        print(f"‚úó –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        return

    # –ì–æ–ª–æ—Å
    voice = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_VOICE
    valid_voices = ["onyx", "nova", "alloy", "echo", "fable", "shimmer"]
    if voice not in valid_voices:
        print(f"‚úó –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≥–æ–ª–æ—Å: {voice}")
        print(f"  –î–æ—Å—Ç—É–ø–Ω—ã–µ: {', '.join(valid_voices)}")
        return

    # API –∫–ª—é—á
    api_key = get_api_key()

    # –ò–º–ø–æ—Ä—Ç OpenAI
    try:
        from openai import OpenAI
    except ImportError:
        print("‚úó openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
        return

    client = OpenAI(api_key=api_key)

    print("=" * 60)
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –ñ–ò–í–û–ì–û –ê–£–î–ò–û ‚Äî OpenAI TTS")
    print("=" * 60)
    print(f"\n–§–∞–π–ª: {input_file.name}")
    print(f"–ú–æ–¥–µ–ª—å: {MODEL}")
    print(f"–ì–æ–ª–æ—Å: {voice}")

    # –ß–∏—Ç–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º
    md_content = input_file.read_text(encoding='utf-8')
    clean_text = clean_text_for_audio(md_content)

    print(f"\n–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(md_content)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"–û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(clean_text)} —Å–∏–º–≤–æ–ª–æ–≤")

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫—É—Å–∫–∏
    chunks = split_into_chunks(clean_text)
    print(f"–ö—É—Å–∫–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {len(chunks)}")

    # –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏: $24 –∑–∞ 1M —Å–∏–º–≤–æ–ª–æ–≤ (tts-1-hd)
    total_chars = sum(len(c) for c in chunks)
    cost = total_chars / 1_000_000 * 24
    print(f"–û–±—â–∏–π –æ–±—ä—ë–º: {total_chars} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"–û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${cost:.3f}")

    # –û—Ü–µ–Ω–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (~150 —Å–ª–æ–≤/–º–∏–Ω)
    word_count = len(clean_text.split())
    est_minutes = word_count / 150
    print(f"–°–ª–æ–≤: {word_count}")
    print(f"–û–∂–∏–¥–∞–µ–º–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: ~{est_minutes:.1f} –º–∏–Ω")

    print(f"\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è...")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—É—Å–∫–∏
    chunk_files = []
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir = Path(tmpdir)

        for i, chunk in enumerate(chunks):
            chunk_file = tmpdir / f"chunk_{i:03d}.mp3"
            print(f"  [{i+1}/{len(chunks)}] {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤...", end=" ")

            if generate_chunk_audio(client, chunk, voice, chunk_file):
                chunk_files.append(chunk_file)
                size_kb = chunk_file.stat().st_size / 1024
                print(f"OK ({size_kb:.0f} KB)")
            else:
                print("–û–®–ò–ë–ö–ê")
                return

        # –°–∫–ª–µ–∏–≤–∞–µ–º
        output_file = input_file.parent / f"{input_file.stem}.mp3"
        print(f"\n–°–∫–ª–µ–∏–≤–∞–Ω–∏–µ {len(chunk_files)} –∫—É—Å–∫–æ–≤...")

        if concatenate_mp3(chunk_files, output_file):
            size_mb = output_file.stat().st_size / (1024 * 1024)
            print(f"‚úì {output_file.name} ({size_mb:.1f} MB)")

            # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ ffprobe
            try:
                result = subprocess.run(
                    ['ffprobe', '-i', str(output_file), '-show_entries',
                     'format=duration', '-v', 'quiet', '-of', 'csv=p=0'],
                    capture_output=True, text=True
                )
                if result.returncode == 0 and result.stdout.strip():
                    dur = float(result.stdout.strip())
                    print(f"‚úì –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {dur/60:.1f} –º–∏–Ω ({dur:.0f} —Å–µ–∫)")
            except FileNotFoundError:
                pass

            print(f"\n{'=' * 60}")
            print("–ì–û–¢–û–í–û")
            print(f"{'=' * 60}")
            print(f"\n–ê—É–¥–∏–æ: {output_file}")
            print(f"\n–ü—Ä–æ—Å–ª—É—à–∞—Ç—å:")
            print(f"  afplay '{output_file}'")
        else:
            print("‚úó –û—à–∏–±–∫–∞ —Å–∫–ª–µ–∏–≤–∞–Ω–∏—è. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ ffmpeg?")


if __name__ == "__main__":
    main()
