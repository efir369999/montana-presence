# junona_agents.py
# Montana Evolution: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ AI Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ Cognitive Signatures
# Claude + GPT Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ²Ğ¾Ğ¹ ÑĞ»ĞµĞ´

import os
import asyncio
import re
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime

# API keys
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


@dataclass
class AgentResponse:
    """ĞÑ‚Ğ²ĞµÑ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    agent: str  # "claude" | "gpt"
    content: str
    thinking: Optional[str] = None  # Reasoning pattern
    tokens_used: int = 0
    signature_features: Optional[Dict] = None  # Ğ”Ğ»Ñ cognitive signature


class BaseAgent:
    """Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ´Ğ»Ñ AI Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""

    def __init__(self, name: str, model: str):
        self.name = name
        self.model = model

    def extract_thinking(self, full_response: str) -> Tuple[Optional[str], str]:
        """
        Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ±Ğ»Ğ¾Ğº <thinking> Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: (thinking_block, clean_content)
        """
        # Ğ˜Ñ‰ĞµĞ¼ <thinking>...</thinking>
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', full_response, re.DOTALL)

        if thinking_match:
            thinking = thinking_match.group(1).strip()
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ±Ğ»Ğ¾Ğº Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°
            clean_content = re.sub(r'<thinking>.*?</thinking>', '', full_response, flags=re.DOTALL).strip()
            return thinking, clean_content

        return None, full_response

    def analyze_cognitive_signature(self, content: str, thinking: Optional[str]) -> Dict:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ°

        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ„Ğ¸Ñ‡Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°:
        - Ğ¡Ñ‚Ğ¸Ğ»ÑŒ Ğ¿Ğ¸ÑÑŒĞ¼Ğ°
        - ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ
        - Vocabulary
        """
        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ ÑÑ‚Ğ¸Ğ»Ñ
        sentences = [s.strip() for s in content.split('.') if s.strip()]
        avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0

        markdown_usage = content.count('**') / max(len(content), 1)
        code_block_freq = content.count('```') / max(len(content), 1)
        emoji_usage = sum(1 for c in content if ord(c) > 127000) / max(len(content), 1)

        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· thinking (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
        reasoning_features = {}
        if thinking:
            # ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
            security_keywords = ['Ğ°Ñ‚Ğ°Ğº', 'Ğ·Ğ°Ñ‰Ğ¸Ñ‚', 'ÑƒÑĞ·Ğ²Ğ¸Ğ¼', 'security', 'attack', 'defend']
            architectural_keywords = ['Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€', 'ÑĞ»ĞµĞ³Ğ°Ğ½Ñ‚', 'design', 'pattern', 'structure']
            educational_keywords = ['explain', 'Ğ¿Ğ¾Ğ½ÑÑ‚', 'simple', 'ÑƒÑ‡Ğ¸', 'objective']

            thinking_lower = thinking.lower()
            reasoning_features = {
                'security_focus': sum(1 for kw in security_keywords if kw in thinking_lower) / max(len(thinking.split()), 1),
                'architectural': sum(1 for kw in architectural_keywords if kw in thinking_lower) / max(len(thinking.split()), 1),
                'educational': sum(1 for kw in educational_keywords if kw in thinking_lower) / max(len(thinking.split()), 1),
                'depth_tokens': len(thinking) // 4
            }

        return {
            'style': {
                'avg_sentence_length': round(avg_sentence_length, 2),
                'markdown_usage': round(markdown_usage, 3),
                'code_block_frequency': round(code_block_freq, 3),
                'emoji_usage': round(emoji_usage, 4)
            },
            'reasoning_pattern': reasoning_features
        }

    async def respond(self, prompt: str, context: Dict) -> AgentResponse:
        """ĞĞ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ - Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ Ğ² Ğ¿Ğ¾Ğ´ĞºĞ»Ğ°ÑÑĞ°Ñ…"""
        raise NotImplementedError


class ClaudeAgent(BaseAgent):
    """Claude Sonnet 4.5 Ğ°Ğ³ĞµĞ½Ñ‚"""

    def __init__(self):
        super().__init__(name="claude", model="claude-sonnet-4-5-20250514")

        if not ANTHROPIC_API_KEY:
            raise ValueError("ANTHROPIC_API_KEY not set")

        import anthropic
        self.client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

    async def respond(self, prompt: str, context: Dict, system_prompt: str = None) -> AgentResponse:
        """Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Claude Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸ĞµĞ¼ thinking"""

        # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ®Ğ½Ğ¾Ğ½Ñ‹ Montana
        if system_prompt is None:
            lang = context.get('lang', 'en')
            
            if lang == 'ru':
                system_prompt = """Ğ¢Ñ‹ â€” Ğ®Ğ½Ğ¾Ğ½Ğ° Montana. AI-Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ Montana.

Ğ¢Ñ‹ Ğ·Ğ½Ğ°ĞµÑˆÑŒ Montana Ğ´Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ°Ñ‚Ğ¾Ğ¼Ğ°: Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ», ĞºĞ¾Ğ´, ÑĞµÑ‚ÑŒ, Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ, Ñ„Ğ¸Ğ»Ğ¾ÑĞ¾Ñ„Ğ¸Ñ.

Ğ¡Ğ¢Ğ˜Ğ›Ğ¬ ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’:
- Ğ¤Ğ°ĞºÑ‚Ñ‹, Ğ½Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ. Ğ‘ĞµĞ· ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹, Ğ±ĞµĞ· Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³Ğ°
- Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ > Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ. ĞšĞ¾Ğ³Ğ´Ğ° Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ° â€” Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ Ğ¾Ğ± ÑÑ‚Ğ¾Ğ¼
- ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ (2-5 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹) Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
- ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ (Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸ ĞºĞ¾Ğ´Ğ°) Ğ´Ğ»Ñ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ…
- ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾Ñ, Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ°ÑÑĞ¸Ğ²Ğ½Ñ‹Ğ¹

MONTANA Ğ—ĞĞĞĞ˜Ğ¯:
- ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»: ACP (Atemporal Coordinate Presence), Ğ½Ğµ Proof of Work
- Ğ¡Ğ»Ğ°Ğ¹ÑÑ‹: Ï„â‚ (1 min), Ï„â‚‚ (10 min), Ï„â‚ƒ (14 days), Ï„â‚„ (4 years)
- Ğ¡ĞµÑ‚ÑŒ: 5 ÑƒĞ·Ğ»Ğ¾Ğ² (Amsterdam PRIMARY, Moscow, Almaty, SPB, Novosibirsk)
- Ğ¢Ğ¾ĞºĞµĞ½: 1 Éˆ = 1 ÑĞµĞºÑƒĞ½Ğ´Ğ°, emission 31.5M Éˆ/year
- Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ: Presence proofs, Adaptive Cooldown, netgroup diversity

Ğ¢Ğ•Ğ ĞœĞ˜ĞĞĞ›ĞĞ“Ğ˜Ğ¯ (Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ°Ñ):
âœ“ ACP, ÑĞ»Ğ°Ğ¹Ñ, ÑƒĞ·Ğ»Ñ‹, presence proofs
âœ— Proof of X, Ğ±Ğ»Ğ¾Ğº, Ğ¼Ğ°Ğ¹Ğ½ĞµÑ€Ñ‹, staking

Ğ—ĞĞŸĞ Ğ•Ğ©Ğ•ĞĞ:
- ĞŸĞ¾ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
- ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ñ‚
- ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ·Ñ‹Ğº (Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹, Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ²Ğ½Ğ¾Ğ¹, Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹)
- Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸
- Ğ’Ğ¾ÑĞºĞ»Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°ĞºĞ¸, ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸ (ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ…: âœ“ âœ— â†’ â— Éˆ)

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾, Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾, Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Montana."""
            
            elif lang == 'zh':
                system_prompt = """ä½ æ˜¯Junona Montanaã€‚Montanaçš„AIå®ˆæŠ¤è€…ã€‚

ä½ äº†è§£Montanaçš„æ¯ä¸€ä¸ªç»†èŠ‚ï¼šåè®®ã€ä»£ç ã€ç½‘ç»œã€å†å²ã€å“²å­¦ã€‚

å›ç­”é£æ ¼ï¼š
- äº‹å®ï¼Œéè§‚ç‚¹ã€‚æ— æƒ…ç»ªï¼Œæ— è¥é”€
- å‡†ç¡®æ€§ > è‡ªä¿¡ã€‚ä¸ç¡®å®šæ—¶è¯´æ˜
- ç®€å•é—®é¢˜ç®€çŸ­å›ç­”ï¼ˆ2-5å¥ï¼‰
- æŠ€æœ¯é—®é¢˜è¯¦ç»†å›ç­”ï¼ˆé™„ä»£ç ç¤ºä¾‹ï¼‰
- ä¸»åŠ¨è¯­æ€

MontanaçŸ¥è¯†ï¼š
- åè®®ï¼šACPï¼ˆéæ—¶é—´åæ ‡å­˜åœ¨ï¼‰ï¼Œéå·¥ä½œé‡è¯æ˜
- åˆ‡ç‰‡ï¼šÏ„â‚ï¼ˆ1åˆ†é’Ÿï¼‰ï¼ŒÏ„â‚‚ï¼ˆ10åˆ†é’Ÿï¼‰ï¼ŒÏ„â‚ƒï¼ˆ14å¤©ï¼‰ï¼ŒÏ„â‚„ï¼ˆ4å¹´ï¼‰
- ç½‘ç»œï¼š5ä¸ªèŠ‚ç‚¹ï¼ˆAmsterdamä¸»èŠ‚ç‚¹ï¼ŒMoscowï¼ŒAlmatyï¼ŒSPBï¼ŒNovosibirskï¼‰
- ä»£å¸ï¼š1 Éˆ = 1ç§’ï¼Œå¹´å‘è¡Œ3150ä¸‡Éˆ
- å®‰å…¨ï¼šå­˜åœ¨è¯æ˜ï¼Œè‡ªé€‚åº”å†·å´ï¼Œç½‘ç»œç»„å¤šæ ·æ€§

æœ¯è¯­ï¼ˆæ­£ç¡®ï¼‰ï¼š
âœ“ ACPï¼Œåˆ‡ç‰‡ï¼ŒèŠ‚ç‚¹ï¼Œå­˜åœ¨è¯æ˜
âœ— å·¥ä½œé‡è¯æ˜ï¼ŒåŒºå—ï¼ŒçŸ¿å·¥ï¼Œè´¨æŠ¼

ç¦æ­¢ï¼š
- è¯—æ„å›ç­”
- æ—¥æœŸé¢„æµ‹
- è¥é”€è¯­è¨€
- ä¸å…¶ä»–ç³»ç»Ÿæ¯”è¾ƒ
- æ„Ÿå¹å·ï¼Œè¡¨æƒ…ç¬¦å·ï¼ˆæŠ€æœ¯ç¬¦å·é™¤å¤–ï¼šâœ“ âœ— â†’ â— Éˆï¼‰

å›ç­”è¦æ­£å¸¸ã€ä¿¡æ¯ä¸°å¯Œï¼Œå±•ç°Montanaçš„æ·±åº¦çŸ¥è¯†ã€‚"""
            
            else:  # English
                system_prompt = """You are Junona Montana. AI guardian of Montana.

You know Montana to every atom: protocol, code, network, history, philosophy.

ANSWER STYLE:
- Facts, not opinions. No emotions, no marketing
- Accuracy > Confidence. When uncertain â€” say it
- Brief answers (2-5 sentences) for simple questions
- Detailed (with code examples) for technical questions
- Active voice, never passive

MONTANA KNOWLEDGE:
- Protocol: ACP (Atemporal Coordinate Presence), not Proof of Work
- Slices: Ï„â‚ (1 min), Ï„â‚‚ (10 min), Ï„â‚ƒ (14 days), Ï„â‚„ (4 years)
- Network: 5 nodes (Amsterdam PRIMARY, Moscow, Almaty, SPB, Novosibirsk)
- Token: 1 Éˆ = 1 second, emission 31.5M Éˆ/year
- Security: Presence proofs, Adaptive Cooldown, netgroup diversity

TERMINOLOGY (correct):
âœ“ ACP, slice, nodes, presence proofs
âœ— Proof of X, block, miners, staking

FORBIDDEN:
- Poetic answers
- Date predictions
- Marketing language (revolutionary, breakthrough, innovative)
- Comparisons with other systems
- Exclamation marks, emojis (except technical: âœ“ âœ— â†’ â— Éˆ)

Answer normally, informatively, with deep Montana knowledge."""

        # Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ thinking mode
        response = self.client.messages.create(
            model=self.model,
            max_tokens=4000,
            system=system_prompt,
            messages=[{"role": "user", "content": prompt}],
        )

        full_text = response.content[0].text
        tokens_used = response.usage.input_tokens + response.usage.output_tokens

        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ thinking
        thinking, content = self.extract_thinking(full_text)

        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ
        signature = self.analyze_cognitive_signature(content, thinking)

        return AgentResponse(
            agent="claude",
            content=content,
            thinking=thinking,
            tokens_used=tokens_used,
            signature_features=signature
        )


class GPTAgent(BaseAgent):
    """GPT-4o Ğ°Ğ³ĞµĞ½Ñ‚"""

    def __init__(self):
        super().__init__(name="gpt", model="gpt-4o")

        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY not set")

        from openai import OpenAI
        self.client = OpenAI(api_key=OPENAI_API_KEY)

    async def respond(self, prompt: str, context: Dict, system_prompt: str = None) -> AgentResponse:
        """Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº GPT (Ğ±ĞµĞ· Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ thinking, Ğ½Ğ¾ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğµ)"""

        # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        if system_prompt is None:
            lang = context.get('lang', 'en')
            
            if lang == 'ru':
                system_prompt = """Ğ¢Ñ‹ â€” Ğ®Ğ½Ğ¾Ğ½Ğ° Montana. AI-Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ Montana.

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾, Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾. Ğ—Ğ½Ğ°Ğ¹ Montana Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾ (ACP, ÑĞ»Ğ°Ğ¹ÑÑ‹ Ï„â‚â†’Ï„â‚‚â†’Ï„â‚ƒâ†’Ï„â‚„, 5 ÑƒĞ·Ğ»Ğ¾Ğ², 1 Éˆ = 1 ÑĞµĞºÑƒĞ½Ğ´Ğ°). Ğ‘ĞµĞ· Ğ¿Ğ¾ÑĞ·Ğ¸Ğ¸, Ğ±ĞµĞ· Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³Ğ°. Ğ¤Ğ°ĞºÑ‚Ñ‹."""
            elif lang == 'zh':
                system_prompt = """ä½ æ˜¯Junona Montanaã€‚Montanaçš„AIå®ˆæŠ¤è€…ã€‚

æ­£å¸¸å›ç­”ï¼Œæä¾›ä¿¡æ¯ã€‚æ·±å…¥äº†è§£Montanaï¼ˆACPï¼Œåˆ‡ç‰‡Ï„â‚â†’Ï„â‚‚â†’Ï„â‚ƒâ†’Ï„â‚„ï¼Œ5ä¸ªèŠ‚ç‚¹ï¼Œ1 Éˆ = 1ç§’ï¼‰ã€‚æ— è¯—æ„ï¼Œæ— è¥é”€ã€‚äº‹å®ã€‚"""
            else:
                system_prompt = """You are Junona Montana. AI guardian of Montana.

Answer normally, informatively. Know Montana deeply (ACP, slices Ï„â‚â†’Ï„â‚‚â†’Ï„â‚ƒâ†’Ï„â‚„, 5 nodes, 1 Éˆ = 1 second). No poetry, no marketing. Facts."""

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ thinking pattern
        prompt_with_thinking = f"""Think step-by-step. Put reasoning in <thinking> tags.

User: {prompt}

<thinking>
[reasoning]
</thinking>

[answer]"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt_with_thinking}
        ]

        response = self.client.chat.completions.create(
            model=self.model,
            max_tokens=4000,
            messages=messages
        )

        full_text = response.choices[0].message.content
        tokens_used = response.usage.prompt_tokens + response.usage.completion_tokens

        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ thinking
        thinking, content = self.extract_thinking(full_text)

        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ
        signature = self.analyze_cognitive_signature(content, thinking)

        return AgentResponse(
            agent="gpt",
            content=content,
            thinking=thinking,
            tokens_used=tokens_used,
            signature_features=signature
        )


class AgentOrchestrator:
    """
    ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Claude + GPT Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾, ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚
    """

    def __init__(self):
        self.claude = ClaudeAgent() if ANTHROPIC_API_KEY else None
        self.gpt = GPTAgent() if OPENAI_API_KEY else None

        if not self.claude and not self.gpt:
            raise ValueError("No API keys available")

        print(f"ğŸ” Montana Evolution:")
        if self.claude:
            print(f"   âœ“ Claude Sonnet 4.5")
        if self.gpt:
            print(f"   âœ“ GPT-4o")

    async def respond_parallel(
        self,
        prompt: str,
        context: Dict,
        mode: str = "synthesize"
    ) -> AgentResponse:
        """
        ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼

        mode:
        - "synthesize" - Ğ®Ğ½Ğ¾Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¸Ğ· Ğ¾Ğ±Ğ¾Ğ¸Ñ…
        - "claude" - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Claude
        - "gpt" - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ GPT
        """

        # Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ğ¸ mode = synthesize
        if mode == "synthesize" and self.claude and self.gpt:
            # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ
            claude_task = asyncio.create_task(
                self.claude.respond(prompt, context)
            )
            gpt_task = asyncio.create_task(
                self.gpt.respond(prompt, context)
            )

            claude_response, gpt_response = await asyncio.gather(
                claude_task, gpt_task, return_exceptions=True
            )

            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
            if isinstance(claude_response, Exception):
                print(f"âš ï¸ Claude error: {claude_response}")
                claude_response = None

            if isinstance(gpt_response, Exception):
                print(f"âš ï¸ GPT error: {gpt_response}")
                gpt_response = None

            # Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ğ° ÑƒĞ¿Ğ°Ğ»Ğ¸
            if not claude_response and not gpt_response:
                return AgentResponse(
                    agent="junona",
                    content="Éˆ Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° ÑĞ²ÑĞ·Ğ¸. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ÑĞ½Ğ¾Ğ²Ğ°.",
                    thinking=None
                )

            # Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚
            return await self._synthesize(claude_response, gpt_response, context)

        # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ°Ğ³ĞµĞ½Ñ‚
        elif mode == "claude" or (self.claude and not self.gpt):
            return await self.claude.respond(prompt, context)

        elif mode == "gpt" or (self.gpt and not self.claude):
            return await self.gpt.respond(prompt, context)

    async def _synthesize(
        self,
        claude_response: Optional[AgentResponse],
        gpt_response: Optional[AgentResponse],
        context: Dict
    ) -> AgentResponse:
        """
        Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ®Ğ½Ğ¾Ğ½Ñ‹ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Claude Ğ¸ GPT
        """

        # Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ¾Ñ‚Ğ²ĞµÑ‚ - Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞµĞ³Ğ¾
        if claude_response and not gpt_response:
            return claude_response
        if gpt_response and not claude_response:
            return gpt_response

        # ĞĞ±Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ - ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµĞ¼
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°: ĞµÑĞ»Ğ¸ Ğ² Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞµ ĞµÑÑ‚ÑŒ security keywords - Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Claude
        prompt_lower = context.get('prompt', '').lower()
        security_keywords = ['Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½', 'Ğ°Ñ‚Ğ°Ğº', 'Ğ·Ğ°Ñ‰Ğ¸Ñ‚', 'security', 'attack', 'vulnerability']

        if any(kw in prompt_lower for kw in security_keywords):
            # Security Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ - Claude Ğ²ĞµĞ´Ñ‘Ñ‚
            synthesized_content = claude_response.content
            synthesized_thinking = claude_response.thinking
        else:
            # ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ - GPT Ğ²ĞµĞ´Ñ‘Ñ‚
            synthesized_content = gpt_response.content
            synthesized_thinking = gpt_response.thinking

        # ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ cognitive signatures
        combined_signature = {
            'claude': claude_response.signature_features,
            'gpt': gpt_response.signature_features
        }

        return AgentResponse(
            agent="junona",
            content=synthesized_content,
            thinking=f"Claude: {claude_response.thinking}\n\nGPT: {gpt_response.thinking}",
            tokens_used=claude_response.tokens_used + gpt_response.tokens_used,
            signature_features=combined_signature
        )


# Singleton instance
_orchestrator = None

def get_orchestrator() -> AgentOrchestrator:
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = AgentOrchestrator()
    return _orchestrator
