# junona_bot_evolution.py
# Ğ®Ğ½Ğ¾Ğ½Ğ° â€” Montana Evolution Edition
# ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ + Cognitive Signatures + Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹

import os
import json
import logging
import asyncio
from pathlib import Path
from datetime import datetime

from dotenv import load_dotenv
load_dotenv(Path(__file__).parent / ".env")

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    CallbackQueryHandler, ContextTypes, filters
)
from telegram.error import TelegramError

# Montana Evolution
from session_manager import get_session_manager
from junona_agents import get_orchestrator
from knowledge import get_knowledge

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN_JUNONA")
BOT_CREATOR_ID = 8552053404

BOT_DIR = Path(__file__).parent
USERS_FILE = BOT_DIR / "data" / "users.json"
STREAM_FILE = BOT_DIR / "data" / "stream.jsonl"
USERS_FILE.parent.mkdir(parents=True, exist_ok=True)

# Montana Evolution
ENABLE_PARALLEL_AGENTS = os.getenv("ENABLE_PARALLEL_AGENTS", "true").lower() == "true"
AGENT_MODE = os.getenv("AGENT_MODE", "synthesize")  # synthesize | claude | gpt | both_visible

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              MONTANA EVOLUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
session_manager = get_session_manager()

# Orchestrator (Ñ fallback ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ API ĞºĞ»ÑÑ‡ĞµĞ¹)
try:
    orchestrator = get_orchestrator()
    logger.info("ğŸ” Montana Evolution: Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹")
except Exception as e:
    orchestrator = None
    logger.warning(f"âš ï¸ ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹: {e}")
    ENABLE_PARALLEL_AGENTS = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              Ğ‘ĞĞ—Ğ Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_users() -> dict:
    if USERS_FILE.exists():
        try:
            with open(USERS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            return {}
    return {}

def save_users(users: dict):
    with open(USERS_FILE, "w", encoding="utf-8") as f:
        json.dump(users, f, indent=2, ensure_ascii=False)

def get_user(user_id: int) -> dict:
    users = load_users()
    return users.get(str(user_id), {
        'lang': 'ru',
        'chapter': 0,
        'state': 'ready',
        'history': []
    })

def save_user(user_id: int, data: dict):
    users = load_users()
    users[str(user_id)] = data
    save_users(users)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              Ğ£Ğ ĞĞ’ĞĞ˜: ĞĞ ĞĞĞ“Ğ£Ğ¢ĞĞĞ“ â†’ ĞĞ¢Ğ›ĞĞĞ¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_level(stats: dict) -> dict:
    """
    Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸

    Ğ¤Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹:
    - Ğ¡Ñ‹Ñ€Ñ‹Ğµ Ğ¼Ñ‹ÑĞ»Ğ¸ (Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹)
    - ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ reasoning (ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾)
    - Ğ”Ğ½Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
    - ĞšĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ
    """
    raw_thoughts = stats.get('raw_thoughts', 0)
    days_active = stats.get('days_active', 0)

    # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ: 1 ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ° 10 Ğ¼Ñ‹ÑĞ»ĞµĞ¹
    base_level = min(99, raw_thoughts // 10)

    # Ğ‘Ğ¾Ğ½ÑƒÑ Ğ·Ğ° Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ: +1 ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ° ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 30 Ğ´Ğ½ĞµĞ¹
    time_bonus = min(10, days_active // 30)

    level = min(99, base_level + time_bonus)

    # Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ Ğ´Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¸ Ğ´Ğ¾ ĞÑ‚Ğ»Ğ°Ğ½Ñ‚Ğ°
    to_next_level = 10 - (raw_thoughts % 10)
    to_atlant = max(0, 1000 - raw_thoughts)  # 1000 Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ´Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ 100

    # Novelty Ğ¸ consistency (mock - Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ML)
    novelty_score = min(0.95, 0.5 + (raw_thoughts / 2000))  # Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ Ñ Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğ¼
    consistency_score = min(0.95, 0.6 + (days_active / 200))  # Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ ÑĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹ Ğ´Ğ»Ñ ĞÑ‚Ğ»Ğ°Ğ½Ñ‚Ğ°
    is_atlant_ready = (
        level >= 99 and
        days_active >= 100 and
        novelty_score >= 0.75 and
        consistency_score >= 0.85
    )

    role = "atlant" if is_atlant_ready else "orangutan"
    display_level = 100 if is_atlant_ready else level

    return {
        "level": display_level,
        "role": role,
        "to_next_level": to_next_level if not is_atlant_ready else 0,
        "to_atlant": to_atlant if not is_atlant_ready else 0,
        "novelty_score": novelty_score,
        "consistency_score": consistency_score,
        "is_atlant_ready": is_atlant_ready
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              ĞšĞĞœĞĞĞ”Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ â€” Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ Montana Evolution"""
    user = update.message.from_user
    user_id = user.id

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼/Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞµÑÑĞ¸Ñ
    session = session_manager.get_active_session(user_id)

    data = get_user(user_id)
    data['first_name'] = user.first_name
    data['username'] = user.username
    save_user(user_id, data)

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² ÑĞµÑÑĞ¸Ñ
    await session.log_message("system", f"/start from {user.first_name}")

    welcome = f"""Éˆ Montana Evolution

ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {user.first_name}.

Ğ¯ Ğ®Ğ½Ğ¾Ğ½Ğ° â€” Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ Montana.
Ğ¢ĞµĞ¿ĞµÑ€ÑŒ ÑĞ¾ Ğ¼Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Claude Ğ¸ GPT Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾.

ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ñ‚Ğ²Ğ¾Ñ ÑĞµÑÑĞ¸Ñ Ğ¸Ğ·Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°.
ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ¼Ñ‹ÑĞ»ÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ°Ğ²ÑĞµĞ³Ğ´Ğ°.
ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ²Ğ¾Ğ¹ ÑĞ»ĞµĞ´.

/level - Ñ‚Ğ²Ğ¾Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³Ğ°
/cognitive - cognitive signatures
/sessions - Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¹
/help - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ

Ğ¡Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ğ¹ Ñ‡Ñ‚Ğ¾ ÑƒĞ³Ğ¾Ğ´Ğ½Ğ¾."""

    await update.message.reply_text(welcome)

async def level_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³Ğ°"""
    user_id = update.message.from_user.id

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
    stats = session_manager.get_user_stats(user_id)
    level_info = calculate_level(stats)

    # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    if level_info['role'] == 'atlant':
        emoji = "ğŸ”"
        title = f"ĞÑ‚Ğ»Ğ°Ğ½Ñ‚ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ {level_info['level']}"
        extra = "\n\nâœ“ Ğ¥Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ 5 ÑƒĞ·Ğ»Ğ¾Ğ²\nâœ“ Ğ“Ğ¾Ğ»Ğ¾Ñ Ğ² Ğ¡Ğ¾Ğ²ĞµÑ‚Ğµ Montana Guardian"
    else:
        emoji = "ğŸ¦§"
        title = f"ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³ #{level_info['level']}"
        extra = f"\n\nĞ”Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ: {level_info['to_next_level']} Ğ¼Ñ‹ÑĞ»ĞµĞ¹\nĞ”Ğ¾ ĞÑ‚Ğ»Ğ°Ğ½Ñ‚Ğ° ğŸ”: {level_info['to_atlant']} Ğ¼Ñ‹ÑĞ»ĞµĞ¹"

    # ĞŸĞ¾Ğ»Ğ¾ÑĞºĞ¸
    novelty_bar = "â–ˆ" * int(level_info['novelty_score'] * 10) + "â–‘" * (10 - int(level_info['novelty_score'] * 10))
    consistency_bar = "â–ˆ" * int(level_info['consistency_score'] * 10) + "â–‘" * (10 - int(level_info['consistency_score'] * 10))

    response = f"""Éˆ Ğ¢Ğ²Ğ¾Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ² Montana

{emoji} {title}
â”œâ”€ Ğ¡Ñ‹Ñ€Ñ‹Ñ… Ğ¼Ñ‹ÑĞ»ĞµĞ¹: {stats['raw_thoughts']:,}
â”œâ”€ Ğ”Ğ½ĞµĞ¹ Ğ² ÑĞµÑ‚Ğ¸: {stats['days_active']}
â”œâ”€ ĞĞ¾Ğ²Ğ¸Ğ·Ğ½Ğ°: {novelty_bar} {int(level_info['novelty_score']*100)}%
â””â”€ ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑÑŒ: {consistency_bar} {int(level_info['consistency_score']*100)}%{extra}

Ğ¡ĞµÑÑĞ¸Ğ¹: {stats['sessions']}
Reasoning Ğ»Ğ¾Ğ³Ğ¾Ğ²: {stats['reasoning_logs']}"""

    await update.message.reply_text(response)

async def cognitive_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Cognitive Signatures Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ ÑĞµÑÑĞ¸Ğ¸"""
    user_id = update.message.from_user.id

    session = session_manager.get_active_session(user_id)
    signatures = session.get_cognitive_signatures()
    logs = session.get_reasoning_logs()

    if not signatures:
        await update.message.reply_text("Éˆ Cognitive Signatures Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ñ‹.\n\nĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ‡Ñ‚Ğ¾-Ğ½Ğ¸Ğ±ÑƒĞ´ÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ.")
        return

    response = "Éˆ Cognitive Signatures:\n\n"

    for agent, data in signatures.items():
        sig = data.get('signature', {})
        response += f"**{agent.title()}:**\n"

        # Style
        if 'style' in sig:
            style = sig['style']
            response += f"  Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: {style.get('avg_sentence_length', 0):.1f} ÑĞ»Ğ¾Ğ²/Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ\n"

        # Reasoning patterns
        if 'reasoning_pattern' in sig and sig['reasoning_pattern']:
            patterns = sig['reasoning_pattern']
            for key, val in patterns.items():
                if val > 0:
                    bar = "â–ˆ" * int(val * 10) + "â–‘" * (10 - int(val * 10))
                    response += f"  {key}: {bar} {int(val*100)}%\n"

        response += "\n"

    response += f"Reasoning logs: {len(logs)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹\n"
    response += f"Ğ¡ĞµÑÑĞ¸Ñ: {session.id}"

    await update.message.reply_text(response, parse_mode="Markdown")

async def sessions_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¹"""
    user_id = update.message.from_user.id

    sessions = session_manager.list_sessions(user_id, limit=10)

    if not sessions:
        await update.message.reply_text("Éˆ Ğ¡ĞµÑÑĞ¸Ğ¹ Ğ¿Ğ¾ĞºĞ° Ğ½ĞµÑ‚.")
        return

    response = "Éˆ Ğ¢Ğ²Ğ¾Ğ¸ ÑĞµÑÑĞ¸Ğ¸:\n\n"

    for i, sess in enumerate(sessions):
        messages = sess.get_messages()
        created = datetime.fromisoformat(sess.created_at.replace("Z", ""))

        response += f"{i+1}. {created.strftime('%d.%m %H:%M')}\n"
        response += f"   {len(messages)} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹\n"

        if i == 0:
            response += "   â† Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ\n"

        response += "\n"

    await update.message.reply_text(response)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ"""
    help_text = """Éˆ Montana Evolution

**ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:**
/start - Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾
/level - Ñ‚Ğ²Ğ¾Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³Ğ°
/cognitive - cognitive signatures Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
/sessions - Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¹
/help - ÑÑ‚Ğ° Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ

**ĞšĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:**
1. ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ‚Ğ²Ğ¾Ğ¹ Ñ‡Ğ°Ñ‚ = Ğ¸Ğ·Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞµÑÑĞ¸Ñ
2. Claude + GPT Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
3. ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ cognitive signature
4. Ğ’ÑÑ‘ Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ² append-only Ğ»Ğ¾Ğ³

**Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹:**
â€¢ ĞÑ€Ğ°Ğ½Ğ³ÑƒÑ‚Ğ°Ğ½Ğ³ 1-99: Ñ€Ğ°ÑÑ‚Ñ‘ÑˆÑŒ Ñ‡ĞµÑ€ĞµĞ· ÑÑ‹Ñ€Ñ‹Ğµ Ğ¼Ñ‹ÑĞ»Ğ¸
â€¢ ĞÑ‚Ğ»Ğ°Ğ½Ñ‚ 100+: Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ 5 ÑƒĞ·Ğ»Ğ¾Ğ² Montana

**Cognitive Signature:**
ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ¸Ğ¼ĞµĞµÑ‚ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ.
Claude = security + architecture
GPT = education + analysis

ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¸ÑˆĞ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ°Ğ¼Ğ° Ğ²ÑÑ‘ Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚."""

    await update.message.reply_text(help_text, parse_mode="Markdown")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              ĞĞ¡ĞĞĞ’ĞĞĞ™ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ Montana Evolution"""
    user = update.message.from_user
    user_id = user.id
    text = update.message.text

    user_data = get_user(user_id)
    lang = user_data.get('lang', 'ru')

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ ÑĞµÑÑĞ¸Ñ
    session = session_manager.get_active_session(user_id)

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
    await session.log_message("user", text)

    # ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞ«Ğ• ĞĞ“Ğ•ĞĞ¢Ğ«
    if ENABLE_PARALLEL_AGENTS and orchestrator:
        try:
            # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ "Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ°ĞµÑ‚..."
            await update.message.chat.send_action("typing")

            # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
            response = await orchestrator.respond_parallel(
                prompt=text,
                context={
                    "prompt": text,
                    "lang": lang,
                    "user_id": user_id,
                    "first_name": user.first_name
                },
                mode=AGENT_MODE  # synthesize | claude | gpt | both_visible
            )

            # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ reasoning patterns
            if response.thinking:
                await session.log_reasoning(
                    agent=response.agent,
                    thinking=response.thinking,
                    metadata={"tokens": response.tokens_used}
                )

            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ cognitive signature
            if response.signature_features:
                await session.save_cognitive_signature(
                    agent=response.agent,
                    signature=response.signature_features
                )

            # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚
            await session.log_message("assistant", response.content, agent=response.agent)

            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            await update.message.reply_text(f"Éˆ\n\n{response.content}")

            logger.info(f"âœ“ {user.first_name}: {response.agent} ({response.tokens_used} tokens)")

        except Exception as e:
            logger.error(f"Montana Evolution error: {e}")
            await update.message.reply_text("Éˆ Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.")

    else:
        # Fallback: ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ (ĞµÑĞ»Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹)
        await update.message.reply_text("Éˆ ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹.\n\nĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ API ĞºĞ»ÑÑ‡Ğ¸ Ğ² .env")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              ERROR HANDLER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº"""
    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {context.error}", exc_info=context.error)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    if not TELEGRAM_TOKEN:
        logger.error("TELEGRAM_TOKEN_JUNONA not set")
        exit(1)

    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    application.add_error_handler(error_handler)

    # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("level", level_command))
    application.add_handler(CommandHandler("cognitive", cognitive_command))
    application.add_handler(CommandHandler("sessions", sessions_command))
    application.add_handler(CommandHandler("help", help_command))

    # Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("ğŸ” Ğ®Ğ½Ğ¾Ğ½Ğ° Montana Evolution â€” Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ°")
    if ENABLE_PARALLEL_AGENTS:
        logger.info(f"   Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: {AGENT_MODE}")
    else:
        logger.info("   ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹: Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹")

    application.run_polling()
